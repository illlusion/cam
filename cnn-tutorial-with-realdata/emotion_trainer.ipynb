{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN training\n",
    "공개 데이터와 keras 라이브러리를 이용해 CNN 모델을 학습해 봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fer 데이터셋을 로컬 저장소로 다운로드 받습니다. shell script를 이용하기 때문에 윈도우 유저는 수동으로 진행해 주세요.\n",
    "데이터 폴더의 구조는 아래와 같습니다.\n",
    "\n",
    "    └── data\n",
    "        └── fer2013\n",
    "            ├── fer2013.csv \n",
    "            ├── ...\n",
    "            └── ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS name: posix\n",
      "['./data/fer2013/fer2013.csv', './data/fer2013/fer2013.bib', './data/fer2013/README']\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# if not 'windows OS', windows can't use shell script\n",
    "# please, download & unzip manually\n",
    "print ('OS name: %s'%os.name)\n",
    "if os.name != 'nt':\n",
    "    if not os.path.exists('./data'):\n",
    "        os.mkdir('./data') # make directory\n",
    "        \n",
    "    subprocess.call('ls ./data', shell=True) # view file list\n",
    "\n",
    "    if not os.path.exists('./data/fer2013.tar'):\n",
    "        subprocess.call('wget https://www.dropbox.com/s/ojuk9bjm4r5bpnt/fer2013.tar -P ./data', \n",
    "                        shell=True) # download dataset\n",
    "    if not os.path.exists('./data/fer2013/fer2013.csv'):\n",
    "        subprocess.call('tar xvf ./data/fer2013.tar -C ./data', shell=True) # unzip\n",
    "print (glob('./data/fer2013/*'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "저장된 데이터파일을 읽습니다.\n",
    "csv 파일에는 이미지 데이터와 라벨이 저장되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       emotion                                             pixels        Usage\n",
      "0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...     Training\n",
      "1            0  151 150 147 155 148 133 111 140 170 174 182 15...     Training\n",
      "2            2  231 212 156 164 174 138 161 173 182 200 106 38...     Training\n",
      "3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...     Training\n",
      "4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...     Training\n",
      "5            2  55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...     Training\n",
      "6            4  20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...     Training\n",
      "7            3  77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...     Training\n",
      "8            3  85 84 90 121 101 102 133 153 153 169 177 189 1...     Training\n",
      "9            2  255 254 255 254 254 179 122 107 95 124 149 150...     Training\n",
      "10           0  30 24 21 23 25 25 49 67 84 103 120 125 130 139...     Training\n",
      "11           6  39 75 78 58 58 45 49 48 103 156 81 45 41 38 49...     Training\n",
      "12           6  219 213 206 202 209 217 216 215 219 218 223 23...     Training\n",
      "13           6  148 144 130 129 119 122 129 131 139 153 140 12...     Training\n",
      "14           3  4 2 13 41 56 62 67 87 95 62 65 70 80 107 127 1...     Training\n",
      "15           5  107 107 109 109 109 109 110 101 123 140 144 14...     Training\n",
      "16           3  14 14 18 28 27 22 21 30 42 61 77 86 88 95 100 ...     Training\n",
      "17           2  255 255 255 255 255 255 255 255 255 255 255 25...     Training\n",
      "18           6  134 124 167 180 197 194 203 210 204 203 209 20...     Training\n",
      "19           4  219 192 179 148 208 254 192 98 121 103 145 185...     Training\n",
      "20           4  1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 7 12 23 45 38 ...     Training\n",
      "21           2  174 51 37 37 38 41 22 25 22 24 35 51 70 83 98 ...     Training\n",
      "22           0  123 125 124 142 209 226 234 236 231 232 235 22...     Training\n",
      "23           0  8 9 14 21 26 32 37 46 52 62 72 70 71 73 76 83 ...     Training\n",
      "24           3  252 250 246 229 182 140 98 72 53 44 67 95 95 8...     Training\n",
      "25           3  224 227 219 217 215 210 187 177 189 200 206 21...     Training\n",
      "26           5  162 200 187 180 197 198 196 192 176 152 136 11...     Training\n",
      "27           0  236 230 225 226 228 209 199 193 196 211 199 19...     Training\n",
      "28           3  210 210 210 210 211 207 147 103 68 60 47 70 12...     Training\n",
      "29           5  50 44 74 141 187 187 169 113 80 128 181 172 76...     Training\n",
      "...        ...                                                ...          ...\n",
      "35857        5  253 255 229 150 89 61 54 60 55 49 61 50 56 45 ...  PrivateTest\n",
      "35858        4  11 11 11 13 20 27 38 41 38 34 20 13 10 39 85 1...  PrivateTest\n",
      "35859        4  11 13 16 27 24 26 89 161 190 197 201 206 210 2...  PrivateTest\n",
      "35860        3  27 42 62 91 112 118 122 123 119 124 129 131 13...  PrivateTest\n",
      "35861        6  233 232 208 188 194 179 177 167 157 180 185 19...  PrivateTest\n",
      "35862        2  73 54 63 76 82 71 67 69 73 72 92 98 117 119 14...  PrivateTest\n",
      "35863        5  196 196 197 197 198 198 198 196 176 148 122 10...  PrivateTest\n",
      "35864        4  68 59 65 78 118 131 137 141 142 135 135 137 13...  PrivateTest\n",
      "35865        3  102 109 109 106 104 107 112 109 116 119 117 12...  PrivateTest\n",
      "35866        6  87 82 59 61 72 102 143 130 90 95 143 173 146 1...  PrivateTest\n",
      "35867        3  198 198 197 196 196 197 196 196 196 195 196 18...  PrivateTest\n",
      "35868        2  204 209 215 218 214 214 214 217 205 175 170 16...  PrivateTest\n",
      "35869        3  217 220 222 223 223 224 225 223 223 225 223 22...  PrivateTest\n",
      "35870        2  6 8 4 5 30 48 61 70 76 79 98 117 130 137 143 1...  PrivateTest\n",
      "35871        6  112 102 98 89 98 133 164 185 180 179 185 169 1...  PrivateTest\n",
      "35872        5  131 159 90 59 10 0 1 1 1 0 1 1 0 0 2 2 5 7 9 1...  PrivateTest\n",
      "35873        4  54 57 77 122 121 76 73 80 58 22 26 27 35 41 66...  PrivateTest\n",
      "35874        5  43 43 51 73 94 97 102 95 99 107 126 144 154 17...  PrivateTest\n",
      "35875        5  248 251 239 144 102 95 82 77 91 138 153 145 14...  PrivateTest\n",
      "35876        6  29 29 27 31 49 56 29 19 22 20 34 43 55 71 85 9...  PrivateTest\n",
      "35877        6  139 143 145 154 159 168 176 181 190 191 195 19...  PrivateTest\n",
      "35878        3  0 39 81 80 104 97 51 64 68 46 41 67 53 68 70 5...  PrivateTest\n",
      "35879        2  0 0 6 16 19 31 47 18 26 19 17 8 15 3 4 2 14 20...  PrivateTest\n",
      "35880        2  164 172 175 171 172 173 178 181 188 192 197 20...  PrivateTest\n",
      "35881        0  181 177 176 156 178 144 136 132 122 107 131 16...  PrivateTest\n",
      "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
      "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
      "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
      "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
      "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest\n",
      "\n",
      "[35887 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "pd_data = pd.read_csv('./data/fer2013/fer2013.csv')\n",
    "print (pd_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Usage에 따라 데이터셋을 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       emotion                                             pixels     Usage\n",
      "0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
      "1            0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
      "2            2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
      "3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
      "4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
      "5            2  55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...  Training\n",
      "6            4  20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...  Training\n",
      "7            3  77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...  Training\n",
      "8            3  85 84 90 121 101 102 133 153 153 169 177 189 1...  Training\n",
      "9            2  255 254 255 254 254 179 122 107 95 124 149 150...  Training\n",
      "10           0  30 24 21 23 25 25 49 67 84 103 120 125 130 139...  Training\n",
      "11           6  39 75 78 58 58 45 49 48 103 156 81 45 41 38 49...  Training\n",
      "12           6  219 213 206 202 209 217 216 215 219 218 223 23...  Training\n",
      "13           6  148 144 130 129 119 122 129 131 139 153 140 12...  Training\n",
      "14           3  4 2 13 41 56 62 67 87 95 62 65 70 80 107 127 1...  Training\n",
      "15           5  107 107 109 109 109 109 110 101 123 140 144 14...  Training\n",
      "16           3  14 14 18 28 27 22 21 30 42 61 77 86 88 95 100 ...  Training\n",
      "17           2  255 255 255 255 255 255 255 255 255 255 255 25...  Training\n",
      "18           6  134 124 167 180 197 194 203 210 204 203 209 20...  Training\n",
      "19           4  219 192 179 148 208 254 192 98 121 103 145 185...  Training\n",
      "20           4  1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 7 12 23 45 38 ...  Training\n",
      "21           2  174 51 37 37 38 41 22 25 22 24 35 51 70 83 98 ...  Training\n",
      "22           0  123 125 124 142 209 226 234 236 231 232 235 22...  Training\n",
      "23           0  8 9 14 21 26 32 37 46 52 62 72 70 71 73 76 83 ...  Training\n",
      "24           3  252 250 246 229 182 140 98 72 53 44 67 95 95 8...  Training\n",
      "25           3  224 227 219 217 215 210 187 177 189 200 206 21...  Training\n",
      "26           5  162 200 187 180 197 198 196 192 176 152 136 11...  Training\n",
      "27           0  236 230 225 226 228 209 199 193 196 211 199 19...  Training\n",
      "28           3  210 210 210 210 211 207 147 103 68 60 47 70 12...  Training\n",
      "29           5  50 44 74 141 187 187 169 113 80 128 181 172 76...  Training\n",
      "...        ...                                                ...       ...\n",
      "28679        6  39 39 39 39 38 30 41 63 105 117 84 97 101 75 5...  Training\n",
      "28680        4  137 146 153 157 164 166 169 172 177 176 176 17...  Training\n",
      "28681        6  208 207 205 206 207 207 210 211 210 207 211 21...  Training\n",
      "28682        2  10 10 10 10 10 10 10 10 10 10 12 2 45 117 122 ...  Training\n",
      "28683        4  178 142 131 130 145 152 125 92 115 142 149 158...  Training\n",
      "28684        3  80 94 86 71 98 74 46 67 105 71 63 76 51 53 80 ...  Training\n",
      "28685        4  94 92 91 92 93 93 92 92 90 90 61 41 34 37 52 6...  Training\n",
      "28686        0  178 184 187 195 199 194 197 205 202 194 201 20...  Training\n",
      "28687        3  114 100 121 166 185 175 160 174 195 205 216 22...  Training\n",
      "28688        3  30 47 52 25 29 48 46 41 70 63 66 49 37 41 35 3...  Training\n",
      "28689        3  181 178 179 171 78 51 56 46 48 50 54 54 68 96 ...  Training\n",
      "28690        2  186 182 173 164 164 177 91 45 66 72 79 79 85 1...  Training\n",
      "28691        4  255 255 255 255 255 255 255 255 255 255 255 25...  Training\n",
      "28692        3  99 103 106 109 112 113 115 118 120 121 115 83 ...  Training\n",
      "28693        6  216 219 216 209 181 104 128 129 134 136 135 14...  Training\n",
      "28694        3  159 195 167 158 152 150 149 154 154 151 149 14...  Training\n",
      "28695        2  84 96 110 132 165 183 175 154 116 95 75 67 63 ...  Training\n",
      "28696        4  0 0 1 1 7 35 76 87 86 90 87 83 89 92 92 93 98 ...  Training\n",
      "28697        3  181 172 161 144 116 109 70 109 187 131 67 30 2...  Training\n",
      "28698        3  35 45 69 79 75 48 45 35 56 93 71 51 48 47 46 4...  Training\n",
      "28699        6  128 134 164 94 70 114 159 138 75 47 89 127 134...  Training\n",
      "28700        4  11 10 12 13 9 11 10 11 11 10 10 13 11 10 11 10...  Training\n",
      "28701        2  34 42 47 34 53 41 33 39 42 38 40 44 41 42 42 4...  Training\n",
      "28702        0  196 194 188 177 156 124 81 60 65 64 84 119 114...  Training\n",
      "28703        5  255 255 255 255 255 255 255 203 145 147 143 14...  Training\n",
      "28704        2  84 85 85 85 85 85 85 85 86 86 86 87 86 86 91 9...  Training\n",
      "28705        0  114 112 113 113 111 111 112 113 115 113 114 11...  Training\n",
      "28706        4  74 81 87 89 95 100 98 93 105 120 127 133 146 1...  Training\n",
      "28707        0  222 227 203 90 86 90 84 77 94 87 99 119 134 14...  Training\n",
      "28708        4  195 199 205 206 205 203 206 209 208 210 212 21...  Training\n",
      "\n",
      "[28709 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "pd_train_data = pd_data[pd_data['Usage']=='Training']\n",
    "pd_val_data = pd_data[pd_data['Usage']=='PublicTest']\n",
    "pd_test_data = pd_data[pd_data['Usage']=='PrivateTest']\n",
    "print (pd_train_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fer 데이터셋은 0~6까지 7개의 class로 나누어져있으며, 순서는 아래와 같습니다.\n",
    "['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "csv파일에는 이미지 데이터가 벡터화 되어있기 때문에 2D 이미지 데이터로 변환하여 각 클래스에 맞는 폴더에 저장해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709,)\n",
      "(28709,)\n",
      "train:(0/28709), ./data/train/00.Angry/000000.png saved!\n",
      "train:(1000/28709), ./data/train/06.Neutral/001000.png saved!\n",
      "train:(2000/28709), ./data/train/06.Neutral/002000.png saved!\n",
      "train:(3000/28709), ./data/train/02.Fear/003000.png saved!\n",
      "train:(4000/28709), ./data/train/04.Sad/004000.png saved!\n",
      "train:(5000/28709), ./data/train/03.Happy/005000.png saved!\n",
      "train:(6000/28709), ./data/train/04.Sad/006000.png saved!\n",
      "train:(7000/28709), ./data/train/04.Sad/007000.png saved!\n",
      "train:(8000/28709), ./data/train/00.Angry/008000.png saved!\n",
      "train:(9000/28709), ./data/train/06.Neutral/009000.png saved!\n",
      "train:(10000/28709), ./data/train/03.Happy/010000.png saved!\n",
      "train:(11000/28709), ./data/train/05.Surprise/011000.png saved!\n",
      "train:(12000/28709), ./data/train/03.Happy/012000.png saved!\n",
      "train:(13000/28709), ./data/train/04.Sad/013000.png saved!\n",
      "train:(14000/28709), ./data/train/06.Neutral/014000.png saved!\n",
      "train:(15000/28709), ./data/train/00.Angry/015000.png saved!\n",
      "train:(16000/28709), ./data/train/01.Disgust/016000.png saved!\n",
      "train:(17000/28709), ./data/train/00.Angry/017000.png saved!\n",
      "train:(18000/28709), ./data/train/00.Angry/018000.png saved!\n",
      "train:(19000/28709), ./data/train/02.Fear/019000.png saved!\n",
      "train:(20000/28709), ./data/train/03.Happy/020000.png saved!\n",
      "train:(21000/28709), ./data/train/02.Fear/021000.png saved!\n",
      "train:(22000/28709), ./data/train/04.Sad/022000.png saved!\n",
      "train:(23000/28709), ./data/train/06.Neutral/023000.png saved!\n",
      "train:(24000/28709), ./data/train/04.Sad/024000.png saved!\n",
      "train:(25000/28709), ./data/train/00.Angry/025000.png saved!\n",
      "train:(26000/28709), ./data/train/05.Surprise/026000.png saved!\n",
      "train:(27000/28709), ./data/train/03.Happy/027000.png saved!\n",
      "train:(28000/28709), ./data/train/06.Neutral/028000.png saved!\n",
      "(3589,)\n",
      "(3589,)\n",
      "val:(0/3589), ./data/val/00.Angry/000000.png saved!\n",
      "val:(1000/3589), ./data/val/02.Fear/001000.png saved!\n",
      "val:(2000/3589), ./data/val/00.Angry/002000.png saved!\n",
      "val:(3000/3589), ./data/val/03.Happy/003000.png saved!\n",
      "(3589,)\n",
      "(3589,)\n",
      "test:(0/3589), ./data/test/00.Angry/000000.png saved!\n",
      "test:(1000/3589), ./data/test/03.Happy/001000.png saved!\n",
      "test:(2000/3589), ./data/test/05.Surprise/002000.png saved!\n",
      "test:(3000/3589), ./data/test/00.Angry/003000.png saved!\n"
     ]
    }
   ],
   "source": [
    "label_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "data_usages = ['train', 'val', 'test']\n",
    "dict_usages = {'train':pd_train_data, 'val':pd_val_data, 'test':pd_test_data}\n",
    "\n",
    "for usage in data_usages:\n",
    "    if not os.path.exists('./data/%s'%usage):\n",
    "        os.mkdir('./data/%s'%usage)\n",
    "        for idx, label_name in enumerate(label_names):\n",
    "            os.mkdir('./data/%s/%02d.%s'%(usage, idx, label_name))\n",
    "\n",
    "    np_data = dict_usages[usage].values\n",
    "    np_images_flatten = np_data[:,1]\n",
    "    np_label = np_data[:,0]\n",
    "\n",
    "    print (np_label.shape)\n",
    "    print (np_images_flatten.shape)\n",
    "\n",
    "    for idx in range(np_label.shape[0]):\n",
    "        if type(np_images_flatten[idx]) != str:\n",
    "            print ('Image is not found, %d'%idx)\n",
    "            continue\n",
    "        img_flatten = np.array(np_images_flatten[idx].split(' ')).astype(np.uint8)\n",
    "        label = np_label[idx]\n",
    "        img_2d = np.reshape(img_flatten, (48,48))\n",
    "        output_label_path = os.path.join('./data',usage,'%02d.%s'%(label, label_names[label]), \n",
    "                                         '%06d.png'%idx)\n",
    "#         cv2.imwrite(output_label_path, img_2d)\n",
    "        if idx%1000==0:\n",
    "            print ('%s:(%d/%d), %s saved!'%(usage, idx, np_label.shape[0], output_label_path))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "데이터가 준비되었으니 keras 라이브러리를 이용해 모델을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, Dropout\n",
    "from keras.layers import BatchNormalization, Dense, GlobalAveragePooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "# from keras.layers import Flatten\n",
    "from keras import layers\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Keras에는 sequential 모델과 functional API 형태의 모델이 제공됩니다.\n",
    "이번 예제에서는 functional API를 사용합니다.\n",
    "\n",
    "Xception 구조를 편집해 모델을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def XCEPTION(input_shape=None, l2_regularization=0.01):\n",
    "    img_size = 48\n",
    "    num_classes = 7\n",
    "\n",
    "    # base\n",
    "    if input_shape is not None:\n",
    "        img_input = Input(input_shape)\n",
    "    else:\n",
    "        img_input = Input((img_size, img_size, 3))\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False)(img_input)\n",
    "    x = BatchNormalization(name='block1_conv1_bn')(x)\n",
    "    x = Activation('relu', name='block1_conv1_act')(x)\n",
    "    x = Conv2D(64, (3, 3), use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block1_conv2_bn')(x)\n",
    "    x = Activation('relu', name='block1_conv2_act')(x)\n",
    "\n",
    "    residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block2_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='block2_sepconv2_act')(x)\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block2_sepconv2_bn')(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    residual = Conv2D(256, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = Activation('relu', name='block3_sepconv1_act')(x)\n",
    "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block3_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='block3_sepconv2_act')(x)\n",
    "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block3_sepconv2_bn')(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "    x = Conv2D(num_classes, (3, 3),\n",
    "            #kernel_regularizer=regularization,\n",
    "            padding='same')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Activation('softmax',name='predictions')(x)\n",
    "\n",
    "    model = Model(img_input, output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "데이터 전처리 함수를 정의합니다.\n",
    "0~255 데이터를 -1~1로 분포하게 만들어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def centering(np_image):\n",
    "    return 2*(np_image - 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "정의된 모델의 객체를 만듭니다.\n",
    "모델(xception cnn network) 학습을 위한 파라미터를 지정합니다.(compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = XCEPTION()\n",
    "model.compile(optimizer=Adam(lr=0.001, decay=1e-6), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "모델에 적용할 학습데이터를 전처리합니다.\n",
    "Keras preprocessing 패키지의 imageDataGenerator를 활용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import argparse\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ImageDataGenerator는 augmentation (rotation, translation 등)을 쉽게 적용할 수 있는 아주 유용한 API입니다.\n",
    "학습에 augmentation을 적용하면 테스트 성능이 향상됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_size = 48\n",
    "batch_size = 100\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=centering,\n",
    "            rescale=1./255,\n",
    "            shear_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            rotation_range=10,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            horizontal_flip=True\n",
    "            )\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=centering,\n",
    "            rescale=1./255\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "            './data/train',\n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=batch_size,\n",
    "            # color_mode='grayscale',\n",
    "            class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "            './data/val',\n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            # color_mode='grayscale',\n",
    "            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "학습할 때 기존에 학습된 weight를 사용할 수 있습니다.\n",
    "이 기술을 transfer learning 이라 부르거나 'fine tuning 한다'라고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] loaded pretrained model weight\n"
     ]
    }
   ],
   "source": [
    "flgUsePretrainedWeight = True\n",
    "if flgUsePretrainedWeight == True:\n",
    "    model.load_weights('./models/xception/weights.20_0.61.h5')\n",
    "    print (\"[*] loaded pretrained model weight\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "학습 결과를 저장하기 위해 디렉토리를 생성하고 model 구조를 json파일 형식으로 export합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 48, 48, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 23, 23, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 23, 23, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 23, 23, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 21, 21, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 21, 21, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 21, 21, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 21, 21, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 21, 21, 128)  512         separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 21, 21, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 21, 21, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 21, 21, 128)  512         separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 11, 11, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 11, 11, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 11, 11, 128)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 11, 11, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 11, 11, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 11, 11, 256)  1024        separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 11, 11, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 11, 11, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 11, 11, 256)  1024        separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 6, 6, 256)    32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 256)    0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 6, 6, 256)    1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 6, 6, 256)    0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 6, 6, 7)      16135       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 7)            0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 209,447\n",
      "Trainable params: 206,951\n",
      "Non-trainable params: 2,496\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./models/new_xception'):\n",
    "    os.mkdir('./models/new_xception')\n",
    "    \n",
    "model_json = model.to_json()\n",
    "with open('./models/new_xception/model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.summary()\n",
    "# plot_model(model, to_file='./models/new_xception/model.png')\n",
    "# graph_model = cv2.imread('./models/new_xception/model.png', 1)\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(graph_model)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "학습 weight를 저장할 callback함수를 구성합니다.\n",
    "원할한 학습을 위해 learning rate 관리 callback도 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "        './models/xception/weights.{epoch:02d}_{val_acc:0.2f}.h5', \n",
    "        save_best_only=False,\n",
    "        verbose=1,\n",
    "        monitor='val_loss',\n",
    "        period= 2, #self.flag.total_epoch // 10 + 1, \n",
    "        save_weights_only=True)\n",
    "\n",
    "def lr_step_decay(epoch):\n",
    "        init_lr = 0.0001\n",
    "        lr_decay = 0.5\n",
    "        epoch_per_decay = 3\n",
    "        lrate = init_lr * math.pow(lr_decay, math.floor((1+epoch)/epoch_per_decay))\n",
    "        # print lrate\n",
    "        return lrate\n",
    "\n",
    "learning_rate = LearningRateScheduler(lr_step_decay)\n",
    "callback_list = [model_checkpoint, learning_rate]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ImageDataGenerator에서 만든 generator data로 모델을 학습합니다.\n",
    "cpu로 실행할 경우 아주 오랜 시간이 필요합니다.\n",
    "i5 macbook에서 약 240분이 소요됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 30/287 [==>...........................] - ETA: 11:03 - loss: 1.0021 - acc: 0.6250"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.n // batch_size,\n",
    "        epochs=20,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=train_generator.n // batch_size,\n",
    "        callbacks=callback_list\n",
    "        )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "여유를 가지고 학습하거나, 특히 gpu를 이용해 보시기를 권장 드립니다."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
